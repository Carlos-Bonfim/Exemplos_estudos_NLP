{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec: Como funciona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Doc2Vec` é uma ferramenta para representação de documentos em forma de vetores, sendo uma extensão do `Word2Vec`.\n",
    "\n",
    "Para fins didáticos, vou utilizar um dataset de *train* e *test* de **Análise de Sentimentos: Emoção no texto** (*tradução livre*) disponibilizado no site [Kaggle](https://www.kaggle.com/c/sa-emotions/data)\n",
    "\n",
    "**Dicionário dos dados**\n",
    "- **id:** Id do post\n",
    "- **sentiment:** Emoção do texto\n",
    "- **content:** texto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\carlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importando para manipulação dos dados\n",
    "import pandas as pd\n",
    "\n",
    "# importando para NLP\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# importando para Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...\n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2     sadness                Funeral ceremony...gloomy friday...\n",
       "3  enthusiasm               wants to hang out with friends SOON!\n",
       "4     neutral  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importando os dados\n",
    "df_train = pd.read_csv('data/train_data.csv')\n",
    "\n",
    "# verificando as primeiras entradas\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados de treino: (30000, 2)\n"
     ]
    }
   ],
   "source": [
    "# checando as dimensões do dataset\n",
    "print(f'Dados de treino: {df_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "worry         7433\n",
       "neutral       6340\n",
       "sadness       4828\n",
       "happiness     2986\n",
       "love          2068\n",
       "surprise      1613\n",
       "hate          1187\n",
       "fun           1088\n",
       "relief        1021\n",
       "empty          659\n",
       "enthusiasm     522\n",
       "boredom        157\n",
       "anger           98\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# verificando por quantidade as emoções classificadas\n",
    "df_train['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>content</th>\n",
       "      <th>lenght_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>empty</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sadness</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neutral</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sentiment                                            content  \\\n",
       "0       empty  @tiffanylue i know  i was listenin to bad habi...   \n",
       "1     sadness  Layin n bed with a headache  ughhhh...waitin o...   \n",
       "2     sadness                Funeral ceremony...gloomy friday...   \n",
       "3  enthusiasm               wants to hang out with friends SOON!   \n",
       "4     neutral  @dannycastillo We want to trade with someone w...   \n",
       "\n",
       "   lenght_content  \n",
       "0              92  \n",
       "1              60  \n",
       "2              35  \n",
       "3              36  \n",
       "4              86  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# olhando a quantidade de elementos que compõe os posts\n",
    "df_train['lenght_content'] = df_train['content'].apply(len)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16759, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# criando uma lista para testar as classificações\n",
    "shortlist = ['neutral', 'happiness', 'worry']\n",
    "\n",
    "# criando um novo conjunto de dados menor\n",
    "df_amostra = df_train[df_train['sentiment'].isin(shortlist)]\n",
    "\n",
    "# checando a nova dimensão\n",
    "df_amostra.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento do texto\n",
    "\n",
    "Tweets são diferentes uns dos outros, portanto devemos considerar:\n",
    "- Remover menções \"@nome\" e talvez url?\n",
    "- Vamos utilizar *TweetTokenizer* ao invés de *regex*\n",
    "- Stopwords, caracteres numericos, como feito normalmente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16759 16759\n"
     ]
    }
   ],
   "source": [
    "# instanciando o TweetTokenizer\n",
    "tweeter = TweetTokenizer(strip_handles=True, preserve_case=False)\n",
    "\n",
    "# definindo stopwords\n",
    "mystopwords = set(stopwords.words('english'))\n",
    "\n",
    "# criando função para remover stopwords e caracteres numericos\n",
    "def remove_stopwords_num(tokens):\n",
    "    return [token for token in tokens if token not in mystopwords and not token.isdigit()]\n",
    "\n",
    "# criando uma função para o pre-processamento\n",
    "def preprocess(texts):\n",
    "    return [remove_stopwords_num(tweeter.tokenize(content)) for content in texts]\n",
    "\n",
    "# passando as funções nos posts\n",
    "my_text = preprocess(df_amostra['content'])\n",
    "\n",
    "# separando as categorias dos sentimentos\n",
    "my_categ = df_amostra['sentiment']\n",
    "\n",
    "# checando as novas dimensões\n",
    "print(len(my_text), len(my_categ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['want', 'trade', 'someone', 'houston', 'tickets', ',', 'one', '.'],\n",
       " ['re-pinging', ':', 'go', 'prom', '?', 'bc', 'bf', 'like', 'friends'],\n",
       " ['hmmm', '.', 'http://www.djhero.com/'],\n",
       " ['cant', 'fall', 'asleep'],\n",
       " ['choked', 'retainers']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checando os primeiros elementos da nova lista dos textos\n",
    "my_text[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12569 4190 12569 4190\n"
     ]
    }
   ],
   "source": [
    "# separando os dados em treino e validação\n",
    "X_train, X_val, y_train, y_val = train_test_split(my_text, my_categ, random_state=1234)\n",
    "print(len(X_train), len(X_val), len(y_train), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TaggedDocument(words=[\"caaaaan't\", 'sleep', '...', '3.30', '!', 'wahhhh', '...', 'wanna', 'cry'], tags=['0']),\n",
       " TaggedDocument(words=['based', 'future', 'forgetting', '/', 'ignoring', 'present', ',', 'best', 'keeper', 'according', 'dhoni', 'parthiv'], tags=['1']),\n",
       " TaggedDocument(words=['good', 'morning', '!', 'early', 'bad', 'conscience', ',', 'trying', 'make', 'taking', 'day', 'yesterday', ',', '?', ':p'], tags=['2']),\n",
       " TaggedDocument(words=['hahaha', \"chivalry's\", 'dead', ',', 'rare'], tags=['3']),\n",
       " TaggedDocument(words=['joining', 'twitter'], tags=['4'])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preparando os dados de treino no formato Doc2Vec\n",
    "train_doc2vec = [TaggedDocument((d), tags=[str(i)]) for i, d in enumerate(X_train)]\n",
    "\n",
    "# visualizando os primeiros elementos\n",
    "train_doc2vec[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "# definindo os parâmetros para o modelo\n",
    "model = Doc2Vec(vector_size=50, alpha=0.025, min_counts=5, dm=1, epochs=100)\n",
    "\n",
    "# instanciando o construtor\n",
    "model.build_vocab(train_doc2vec)\n",
    "\n",
    "# treinando o modelo, somente com os dados de treino!\n",
    "model.train(train_doc2vec, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# salvando o modelo\n",
    "model.save('d2v.model')\n",
    "print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   happiness       0.34      0.55      0.42       713\n",
      "     neutral       0.47      0.53      0.50      1595\n",
      "       worry       0.61      0.41      0.49      1882\n",
      "\n",
      "    accuracy                           0.48      4190\n",
      "   macro avg       0.47      0.49      0.47      4190\n",
      "weighted avg       0.51      0.48      0.48      4190\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# importando o modelo treinado se precisar\n",
    "model = Doc2Vec.load('d2v.model')\n",
    "\n",
    "# inferindo o modelo em várias etapas para uma representação estável\n",
    "train_vectors = [model.infer_vector(list_of_tokens, steps=50) for list_of_tokens in X_train]\n",
    "test_vectors = [model.infer_vector(list_of_tokens, steps=50) for list_of_tokens in X_val]\n",
    "\n",
    "# instanciando o Logistic Regression\n",
    "logreg = LogisticRegression(class_weight=\"balanced\")\n",
    "logreg.fit(train_vectors, y_train)\n",
    "\n",
    "# realizando as previsões\n",
    "y_pred = logreg.predict(test_vectors)\n",
    "\n",
    "# analisando o classification report\n",
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referência\n",
    "https://github.com/practical-nlp/practical-nlp/blob/master/Ch4/02_Doc2Vec_Example.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
